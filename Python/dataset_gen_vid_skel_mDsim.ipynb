{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 15:07:31.852160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-10 15:07:32.042049: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-10 15:07:32.796740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/emre/anaconda3/envs/emre_venv/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-10-10 15:07:32.796840: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/emre/anaconda3/envs/emre_venv/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-10-10 15:07:32.796851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be created: /mnt/HDD04/ICASSP_2023/Scripts/datasets/ASL_10_vid_skel_mDsim.pkl\n"
     ]
    }
   ],
   "source": [
    "import glob, h5py, pickle, cv2, re\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mat73\n",
    "from IPython.display import clear_output\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "width = 128\n",
    "height = 128\n",
    "channels = 3\n",
    "\n",
    "num_class = 10\n",
    "sub = 'ASL_' + str(num_class) + '_vid_skel_mDsim'\n",
    "filename = '/mnt/HDD04/ICASSP_2023/Scripts/datasets/'+sub+'.pkl'\n",
    "print('File to be created: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. env files: 2240\n"
     ]
    }
   ],
   "source": [
    "env_path = '/mnt/HDD04/ICASSP_2023/Data/envelopes_sim/'\n",
    "env_threshold = 2e3\n",
    "vid_path = '/mnt/HDD04/Gallaudet_exp1_fusion_data/videos/'\n",
    "skel_path = env_path.replace('envelopes_sim', 'skeletons_mat')\n",
    "md_path = env_path.replace('envelopes_sim', 'microDoppler_sim')\n",
    "\n",
    "env_files = glob.glob(env_path + '*txt')\n",
    "print('Num. env files:', len(env_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'125': 30, '121': 30, '122': 30, '123': 25, '117': 25, '119': 25, '131': 25, '128': 25, '129': 25, '118': 25}\n",
      "select_classes: dict_keys(['125', '121', '122', '123', '117', '119', '131', '128', '129', '118'])\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "clas_dict = dict()\n",
    "for e in env_files:\n",
    "    fname = e.split('/')[-1]\n",
    "    underscore_idx = [m.start() for m in re.finditer('_', fname)]\n",
    "    word_id = fname.find('word')\n",
    "    clas = fname[word_id+4:underscore_idx[-1]]\n",
    "    if clas not in clas_dict:\n",
    "        clas_dict[clas] = 1\n",
    "    else:\n",
    "        clas_dict[clas] += 1\n",
    "sorted_clas_dict = {k: v for k, v in sorted(clas_dict.items(), key=lambda item: item[1])}\n",
    "reverse =dict(reversed(list(sorted_clas_dict.items())))\n",
    "# select the ones with most samples\n",
    "sorted_clas_dict = dict(itertools.islice(reverse.items(), num_class))\n",
    "print(sorted_clas_dict)\n",
    "select_classes = sorted_clas_dict.keys()\n",
    "print('select_classes:', select_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = {'125': 0, '121': 1, '122': 2, '123': 3, '117': 4,\n",
    "               '119': 5, '131': 6, '128': 7, '129': 8, '118': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return np.array(dataframe.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrameCapture(path): \n",
    "      \n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "    video_length = int(vidObj.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     print (\"Number of frames: \", video_length)\n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "    success, frame = vidObj.read() \n",
    "    # checks whether frames were extracted \n",
    "#     success = 1\n",
    "    frames = []\n",
    "    while success: \n",
    "  \n",
    "        resized = cv2.resize(frame, (width,height), interpolation = cv2.INTER_LINEAR)\n",
    "        success, frame = vidObj.read() \n",
    "#         print('Read a new frame: ', success)\n",
    "        frames.append(resized) # .resized(width,height)\n",
    "        count += 1\n",
    "        if (count > (video_length-1)):\n",
    "            break\n",
    "    result = np.array([frames[i] for i in range(len(frames))])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, test_files = train_test_split(env_files, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training file: 1783/1792\n",
      "(210, 128, 128, 3)\n",
      "(210,)\n",
      "(210, 10)\n",
      "(210,)\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_vids = []\n",
    "train_skels = []\n",
    "train_labels = []\n",
    "\n",
    "for i, e in enumerate(train_files):\n",
    "    \n",
    "    fname = e.split('/')[-1]\n",
    "    underscore_idx = [m.start() for m in re.finditer('_', fname)]\n",
    "    word_id = fname.find('word')\n",
    "    clas = fname[word_id+4:underscore_idx[-1]]\n",
    "    \n",
    "    if clas not in select_classes:\n",
    "        continue\n",
    "        \n",
    "    # read envelope\n",
    "    env = load_file(e)\n",
    "    if sum(env[0]) < env_threshold:\n",
    "        continue\n",
    "        \n",
    "    # read video\n",
    "    vid_name = vid_path + fname.replace('txt', 'avi')\n",
    "    vid = FrameCapture(vid_name)\n",
    "    num_frames = vid.shape[0]\n",
    "    train_vids.append(np.array(vid))\n",
    "    \n",
    "    # read skeleton\n",
    "    skel_name = skel_path + fname.replace('txt', 'mat')\n",
    "    skel = loadmat(skel_name)['hands']\n",
    "    skel = np.transpose(skel, [2, 1, 0])\n",
    "    skel = skel[3:]\n",
    "    \n",
    "    # pad missing frames\n",
    "    if skel.shape[0] < num_frames:\n",
    "        skel = np.concatenate([skel, np.tile(np.expand_dims(skel[0], 0), [num_frames - skel.shape[0], 1, 1])])\n",
    "    train_skels.append(skel)\n",
    "    \n",
    "    # read microDoppler\n",
    "    md_name = md_path + fname.replace('txt', 'png')\n",
    "    img = cv2.imread(md_name)\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC) # resize to (128,128)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    clear_output(wait=True)\n",
    "    print('Processing training file: '+ str(i+1) + '/' + str(len(train_files)))\n",
    "    train_images.append(img)\n",
    "    train_labels.append(new_classes[clas])\n",
    "\n",
    "train_labels = to_categorical(np.array(train_labels, dtype=object), num_class)\n",
    "train_images = np.swapaxes(np.array(train_images, dtype=object), 1, 2).reshape(len(train_images), width, height, channels)/255.\n",
    "train_vids = np.array(train_vids, dtype=object)/255.\n",
    "train_skels = np.array(train_skels, dtype=object)\n",
    "print(train_images.shape)\n",
    "print(train_skels.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_vids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training file: 437/448\n",
      "(55, 128, 128, 3)\n",
      "(55,)\n",
      "(55, 10)\n",
      "(55,)\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "test_vids = []\n",
    "test_skels = []\n",
    "test_labels = []\n",
    "\n",
    "for i, e in enumerate(test_files):\n",
    "    \n",
    "    fname = e.split('/')[-1]\n",
    "    underscore_idx = [m.start() for m in re.finditer('_', fname)]\n",
    "    word_id = fname.find('word')\n",
    "    clas = fname[word_id+4:underscore_idx[-1]]\n",
    "    \n",
    "    if clas not in select_classes:\n",
    "        continue\n",
    "    \n",
    "    # read envelope\n",
    "    env = load_file(e)\n",
    "    if sum(env[0]) < env_threshold:\n",
    "        continue\n",
    "        \n",
    "    # read video\n",
    "    vid_name = vid_path + fname.replace('txt', 'avi')\n",
    "    vid = FrameCapture(vid_name)\n",
    "    num_frames = vid.shape[0]\n",
    "    test_vids.append(np.array(vid))\n",
    "    \n",
    "    # read skeleton\n",
    "    skel_name = skel_path + fname.replace('txt', 'mat')\n",
    "    skel = loadmat(skel_name)['hands']\n",
    "    skel = np.transpose(skel, [2, 1, 0])\n",
    "    skel = skel[3:]\n",
    "    \n",
    "    # pad missing frames\n",
    "    if skel.shape[0] < num_frames:\n",
    "        skel = np.concatenate([skel, np.tile(np.expand_dims(skel[0], 0), [num_frames - skel.shape[0], 1, 1])])\n",
    "    test_skels.append(skel)\n",
    "    \n",
    "    # read microDoppler\n",
    "    md_name = md_path + fname.replace('txt', 'png')\n",
    "    img = cv2.imread(md_name)\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC) # resize to (128,128)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    clear_output(wait=True)\n",
    "    print('Processing training file: '+ str(i+1) + '/' + str(len(test_files)))\n",
    "    test_images.append(img)\n",
    "    test_labels.append(new_classes[clas])\n",
    "\n",
    "test_labels = to_categorical(np.array(test_labels, dtype=object), num_class)\n",
    "test_images = np.swapaxes(np.array(test_images, dtype=object), 1, 2).reshape(len(test_images), width, height, channels)/255.\n",
    "test_vids = np.array(test_vids, dtype=object)/255.\n",
    "test_skels = np.array(test_skels, dtype=object)\n",
    "print(test_images.shape)\n",
    "print(test_skels.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_vids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/HDD04/ICASSP_2023/Scripts/datasets/ASL_10_vid_skel_mDsim.pkl created.\n"
     ]
    }
   ],
   "source": [
    "data = [train_images, train_vids, train_skels, train_labels, \n",
    "        test_images, test_vids, test_skels, test_labels]\n",
    "with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(data, output, pickle.HIGHEST_PROTOCOL)\n",
    "print(filename+' created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
