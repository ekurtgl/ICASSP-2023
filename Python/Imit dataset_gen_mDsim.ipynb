{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File to be created: /mnt/HDD04/ICASSP_2023/Scripts/datasets/imit_ASL_10_mDsim_224x224.pkl\n"
     ]
    }
   ],
   "source": [
    "import glob, h5py, pickle, cv2, re\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mat73\n",
    "from IPython.display import clear_output\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "width = 224\n",
    "height = 224\n",
    "channels = 3\n",
    "\n",
    "num_class = 10\n",
    "sub = 'imit_ASL_' + str(num_class) + '_mDsim_224x224'\n",
    "filename = '/mnt/HDD04/ICASSP_2023/Scripts/datasets/'+sub+'.pkl'\n",
    "print('File to be created: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. env files: 0\n",
      "Num. files: 1924\n"
     ]
    }
   ],
   "source": [
    "env_path = '/mnt/HDD04/ASL_10_imit/outputs/envelopes_sim/'\n",
    "env_threshold = 2e3\n",
    "err_path = '/mnt/HDD04/ASL_10_imit/scripts/err_files.txt'\n",
    "vid_path = '/mnt/HDD04/ASL_10_imit/outputs/webcam/cut/'\n",
    "skel_path = env_path.replace('envelopes_sim', 'skeletons_mat')\n",
    "md_path = vid_path.replace('webcam/cut', 'microDoppler_sim')\n",
    "\n",
    "md_files = glob.glob(md_path + '*png')\n",
    "env_files = glob.glob(env_path + '*txt')\n",
    "fnames = [m.split('/')[-1][:-4] for m in md_files]\n",
    "print('Num. env files:', len(env_files))\n",
    "print('Num. files:', len(fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# clas_dict = dict()\n",
    "# for e in env_files:\n",
    "#     fname = e.split('/')[-1]\n",
    "#     underscore_idx = [m.start() for m in re.finditer('_', fname)]\n",
    "#     word_id = fname.find('word')\n",
    "#     clas = fname[word_id+4:underscore_idx[-1]]\n",
    "#     if clas not in clas_dict:\n",
    "#         clas_dict[clas] = 1\n",
    "#     else:\n",
    "#         clas_dict[clas] += 1\n",
    "# sorted_clas_dict = {k: v for k, v in sorted(clas_dict.items(), key=lambda item: item[1])}\n",
    "# reverse =dict(reversed(list(sorted_clas_dict.items())))\n",
    "# # select the ones with most samples\n",
    "# sorted_clas_dict = dict(itertools.islice(reverse.items(), num_class))\n",
    "# print(sorted_clas_dict)\n",
    "# select_classes = sorted_clas_dict.keys()\n",
    "# print('select_classes:', select_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = {'125': 0, '121': 1, '122': 2, '123': 3, '117': 4,\n",
    "               '119': 5, '131': 6, '128': 7, '129': 8, '118': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return np.array(dataframe.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrameCapture(path): \n",
    "      \n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "    video_length = int(vidObj.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     print (\"Number of frames: \", video_length)\n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "    success, frame = vidObj.read() \n",
    "    # checks whether frames were extracted \n",
    "#     success = 1\n",
    "    frames = []\n",
    "    while success: \n",
    "  \n",
    "        resized = cv2.resize(frame, (width,height), interpolation = cv2.INTER_LINEAR)\n",
    "        success, frame = vidObj.read() \n",
    "#         print('Read a new frame: ', success)\n",
    "        frames.append(resized) # .resized(width,height)\n",
    "        count += 1\n",
    "        if (count > (video_length-1)):\n",
    "            break\n",
    "    result = np.array([frames[i] for i in range(len(frames))])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022_10_13_12_52_55_subjLadi_Exp0_class125_part5_word125_cnt8',\n",
       " '2022_10_13_13_00_54_subjLadi_Exp0_class122_part1_word122_cnt9',\n",
       " '2022_10_13_13_04_32_subjLadi_Exp0_class123_part3_word123_cnt8',\n",
       " '2022_10_13_13_04_32_subjLadi_Exp0_class123_part4_word123_cnt9',\n",
       " '2022_10_13_13_13_51_subjLadi_Exp0_class119_part4_word119_cnt12']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(err_path, 'r') as err:\n",
    "    err_files = []\n",
    "    for line in err:\n",
    "        err_files.append(line.split(\",\")[0][:-1])\n",
    "err_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1924\n",
      "2022_10_13_16_12_38_subjEmre_Exp0_class128_part2_word128_cnt5\n",
      "2022_10_13_13_26_55_subjLadi_Exp0_class118_part4_word118_cnt10\n",
      "2022_10_13_15_32_17_subjSean_Exp0_class125_part1_word125_cnt11\n",
      "2022_10_13_16_19_32_subjEmre_Exp0_class118_part1_word118_cnt6\n",
      "2022_10_13_16_16_32_subjEmre_Exp0_class129_part5_word129_cnt3\n"
     ]
    }
   ],
   "source": [
    "# remove md files which doesn't have corresponding vid file due to labeling error\n",
    "for f in fnames:\n",
    "    if f in err_files:\n",
    "        fnames.remove(f)\n",
    "print(len(fnames))\n",
    "\n",
    "for f in fnames[:5]:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, test_files = train_test_split(fnames, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training file: 1539/1539\n",
      "(1539, 3, 224, 224)\n",
      "(1539, 10)\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_vids = []\n",
    "train_skels = []\n",
    "train_labels = []\n",
    "\n",
    "for i, f in enumerate(train_files):\n",
    "    \n",
    "    underscore_idx = [m.start() for m in re.finditer('_', f)]\n",
    "    word_id = f.find('word')\n",
    "    clas = f[word_id+4:underscore_idx[-1]]\n",
    "    \n",
    "    if clas not in new_classes:\n",
    "        continue\n",
    "        \n",
    "    # read envelope\n",
    "#     env = load_file(e)\n",
    "#     if sum(env[0]) < env_threshold:\n",
    "#         continue\n",
    "        \n",
    "    # read video\n",
    "#     vid_name = vid_path + fname.replace('txt', 'avi')\n",
    "#     vid = FrameCapture(vid_name)\n",
    "#     num_frames = vid.shape[0]\n",
    "#     train_vids.append(np.array(vid))\n",
    "    \n",
    "    # read skeleton\n",
    "#     skel_name = skel_path + fname.replace('txt', 'mat')\n",
    "#     skel = loadmat(skel_name)['hands']\n",
    "#     skel = np.transpose(skel, [2, 1, 0])\n",
    "#     skel = skel[3:]\n",
    "    \n",
    "    # pad missing frames\n",
    "#     if skel.shape[0] < num_frames:\n",
    "#         skel = np.concatenate([skel, np.tile(np.expand_dims(skel[0], 0), [num_frames - skel.shape[0], 1, 1])])\n",
    "#     train_skels.append(skel)\n",
    "    \n",
    "    # read microDoppler\n",
    "    md_name = md_path + f + '.png'\n",
    "    img = cv2.imread(md_name)\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC) # resize to (128,128)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    clear_output(wait=True)\n",
    "    print('Processing training file: '+ str(i+1) + '/' + str(len(train_files)))\n",
    "    train_images.append(img)\n",
    "    train_labels.append(new_classes[clas])\n",
    "\n",
    "train_labels = to_categorical(np.array(train_labels), num_class)\n",
    "train_images = np.swapaxes(np.array(train_images), 1, 2).reshape(len(train_images), width, height, channels)/255.\n",
    "train_images = np.swapaxes(train_images, 1, 3)\n",
    "# train_vids = np.array(train_vids, dtype=object)/255.\n",
    "# train_skels = np.array(train_skels, dtype=object)\n",
    "print(train_images.shape)\n",
    "# print(train_skels.shape)\n",
    "print(train_labels.shape)\n",
    "# print(train_vids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing testing file: 385/385\n",
      "(385, 3, 224, 224)\n",
      "(385, 10)\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "test_vids = []\n",
    "test_skels = []\n",
    "test_labels = []\n",
    "\n",
    "for i, f in enumerate(test_files):\n",
    "    \n",
    "    underscore_idx = [m.start() for m in re.finditer('_', f)]\n",
    "    word_id = f.find('word')\n",
    "    clas = f[word_id+4:underscore_idx[-1]]\n",
    "    if clas not in new_classes:\n",
    "        continue\n",
    "    # read envelope\n",
    "#     env = load_file(e)\n",
    "#     if sum(env[0]) < env_threshold:\n",
    "#         continue\n",
    "        \n",
    "    # read video\n",
    "#     vid_name = vid_path + fname.replace('txt', 'avi')\n",
    "#     vid = FrameCapture(vid_name)\n",
    "#     num_frames = vid.shape[0]\n",
    "#     test_vids.append(np.array(vid))\n",
    "    \n",
    "    # read skeleton\n",
    "#     skel_name = skel_path + fname.replace('txt', 'mat')\n",
    "#     skel = loadmat(skel_name)['hands']\n",
    "#     skel = np.transpose(skel, [2, 1, 0])\n",
    "#     skel = skel[3:]\n",
    "    \n",
    "    # pad missing frames\n",
    "#     if skel.shape[0] < num_frames:\n",
    "#         skel = np.concatenate([skel, np.tile(np.expand_dims(skel[0], 0), [num_frames - skel.shape[0], 1, 1])])\n",
    "#     test_skels.append(skel)\n",
    "    \n",
    "    # read microDoppler\n",
    "    md_name = md_path + f + '.png'\n",
    "    img = cv2.imread(md_name)\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC) # resize to (128,128)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    clear_output(wait=True)\n",
    "    print('Processing testing file: '+ str(i+1) + '/' + str(len(test_files)))\n",
    "    test_images.append(img)\n",
    "    test_labels.append(new_classes[clas])\n",
    "\n",
    "test_labels = to_categorical(np.array(test_labels), num_class)\n",
    "test_images = np.swapaxes(np.array(test_images), 1, 2).reshape(len(test_images), width, height, channels)/255.\n",
    "test_images = np.swapaxes(test_images, 1, 3)\n",
    "# test_vids = np.array(test_vids, dtype=object)/255.\n",
    "# test_skels = np.array(test_skels, dtype=object)\n",
    "print(test_images.shape)\n",
    "# print(test_skels.shape)\n",
    "print(test_labels.shape)\n",
    "# print(test_vids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(test_labels, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/HDD04/ICASSP_2023/Scripts/datasets/imit_ASL_10_mDsim_224x224.pkl created.\n"
     ]
    }
   ],
   "source": [
    "# data = [train_images, train_vids, train_skels, train_labels, \n",
    "#         test_images, test_vids, test_skels, test_labels]\n",
    "data = [train_images, train_labels, train_files,\n",
    "        test_images, test_labels, test_files]\n",
    "\n",
    "with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(data, output, pickle.HIGHEST_PROTOCOL)\n",
    "print(filename+' created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
